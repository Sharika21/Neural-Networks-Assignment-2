{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "027c660e-b508-43ab-8360-a8928ba190be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Imports ####\n",
    "from itertools import product\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "446fa6a7-a439-4998-8e2c-7fcf4fa7a4d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Length (major axis)  Width (minor axis)  Thickness (depth)     Area  \\\n",
      "0              290.609274          227.940628         127.759132  22619.0   \n",
      "1              290.609274          234.188126         128.199509  23038.0   \n",
      "2              290.609274          229.418610         125.796547  22386.5   \n",
      "3              290.609274          232.763153         125.918808  22578.5   \n",
      "4              290.609274          230.150742         107.253448  19068.0   \n",
      "...                   ...                 ...                ...      ...   \n",
      "2798           290.609274          192.709366         122.356506  18471.5   \n",
      "2799           290.609274          186.254745         118.708961  17213.5   \n",
      "2800           290.609274          186.196182         119.147224  17510.5   \n",
      "2801           290.609274          188.660828         120.634438  17941.0   \n",
      "2802           269.356903          176.023636         109.705378  36683.5   \n",
      "\n",
      "       Perimeter  Roundness  Solidity  Compactness  Aspect Ratio  \\\n",
      "0     643.813269   0.470466  0.973384     1.458265      1.274934   \n",
      "1     680.984841   0.470466  0.957304     1.601844      1.240922   \n",
      "2     646.943212   0.470466  0.967270     1.487772      1.266721   \n",
      "3     661.227483   0.470466  0.965512     1.540979      1.248519   \n",
      "4     624.842706   0.470466  0.951450     1.629395      1.262691   \n",
      "...          ...        ...       ...          ...           ...   \n",
      "2798  653.345233   0.470466  0.931000     1.838965      1.508018   \n",
      "2799  581.688379   0.470466  0.952706     1.564234      1.560278   \n",
      "2800  608.315795   0.470466  0.948821     1.681705      1.560769   \n",
      "2801  630.759446   0.470466  0.944810     1.764701      1.540380   \n",
      "2802  887.310743   0.643761  0.947380     1.707933      1.530231   \n",
      "\n",
      "      Eccentricity    Extent  Convex hull(convex area)  Type  \n",
      "0         0.620313  0.681193                   23237.5     0  \n",
      "1         0.592117  0.656353                   24065.5     0  \n",
      "2         0.613828  0.683620                   23144.0     0  \n",
      "3         0.598733  0.685360                   23385.0     0  \n",
      "4         0.610574  0.714800                   20041.0     0  \n",
      "...            ...       ...                       ...   ...  \n",
      "2798      0.748511  0.725739                   19840.5     2  \n",
      "2799      0.767615  0.714016                   18068.0     2  \n",
      "2800      0.767783  0.718999                   18455.0     2  \n",
      "2801      0.760626  0.738191                   18989.0     2  \n",
      "2802      0.756930  0.722429                   38721.0     2  \n",
      "\n",
      "[2790 rows x 13 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SharikaNarsing\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: invalid value encountered in sqrt\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "#### Pre-processing ####################################################################################################################################################\n",
    "\n",
    "#### Load the dataset ####\n",
    "df = pd.read_csv('almond.csv')\n",
    "# print(df.head())\n",
    "\n",
    "#### Drop first column ####\n",
    "df = df.drop(df.columns[0], axis=1)\n",
    "# print(df.head())\n",
    "\n",
    "#### Handle missing values with mean ####\n",
    "missing_values_columns = ['Length (major axis)', 'Width (minor axis)', 'Thickness (depth)', 'Area', 'Perimeter', 'Roundness', 'Solidity', 'Compactness', 'Extent', 'Convex hull(convex area)']\n",
    "df[missing_values_columns] = df[missing_values_columns].fillna(df[missing_values_columns].mean())\n",
    "# print(df.head())\n",
    "\n",
    "#### Impute the aspect ratio: length/ width & eccentricity: sqrt(1 - ( Width / Length ) **2 ) ####\n",
    "df['Aspect Ratio'] = df['Length (major axis)'] / df['Width (minor axis)']\n",
    "df['Eccentricity'] = np.sqrt(1 - (df['Width (minor axis)'] / df['Length (major axis)']) ** 2)\n",
    "# print(df.head())\n",
    "\n",
    "#### Convert 'Type' from categorical values to numerical ####\n",
    "label_encoder = LabelEncoder()\n",
    "df['Type'] = label_encoder.fit_transform(df['Type'])\n",
    "# print(df.head())\n",
    "\n",
    "#### Check for negative values ####\n",
    "df = df[(df >= 0).all(axis=1)]\n",
    "# negative_values = df[df < 0]\n",
    "# print(\"Rows with negative values in any column:\")\n",
    "# print(df[(df < 0).any(axis=1)])\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be9adac5-f757-483f-8730-113398a89147",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (1953, 12)\n",
      "x_test shape: (837, 12)\n",
      "y_train shape: (1953,)\n",
      "y_test shape: (837,)\n"
     ]
    }
   ],
   "source": [
    "#### Split the dataset #################################################################################################################################################\n",
    "x = df.drop('Type', axis=1)\n",
    "y = df['Type']\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=42)\n",
    "\n",
    "print(\"x_train shape:\", x_train.shape)\n",
    "print(\"x_test shape:\", x_test.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"y_test shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "64dd668c-869b-4ff4-a252-5966cf65126c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Length (major axis)  Width (minor axis)  Thickness (depth)     Area  \\\n",
      "0              290.609274          227.940628         127.759132  22619.0   \n",
      "1              290.609274          234.188126         128.199509  23038.0   \n",
      "2              290.609274          229.418610         125.796547  22386.5   \n",
      "3              290.609274          232.763153         125.918808  22578.5   \n",
      "4              290.609274          230.150742         107.253448  19068.0   \n",
      "...                   ...                 ...                ...      ...   \n",
      "2798           290.609274          192.709366         122.356506  18471.5   \n",
      "2799           290.609274          186.254745         118.708961  17213.5   \n",
      "2800           290.609274          186.196182         119.147224  17510.5   \n",
      "2801           290.609274          188.660828         120.634438  17941.0   \n",
      "2802           269.356903          176.023636         109.705378  36683.5   \n",
      "\n",
      "       Perimeter  Roundness  Solidity  Compactness  Aspect Ratio  \\\n",
      "0     643.813269   0.470466  0.973384     1.458265      1.274934   \n",
      "1     680.984841   0.470466  0.957304     1.601844      1.240922   \n",
      "2     646.943212   0.470466  0.967270     1.487772      1.266721   \n",
      "3     661.227483   0.470466  0.965512     1.540979      1.248519   \n",
      "4     624.842706   0.470466  0.951450     1.629395      1.262691   \n",
      "...          ...        ...       ...          ...           ...   \n",
      "2798  653.345233   0.470466  0.931000     1.838965      1.508018   \n",
      "2799  581.688379   0.470466  0.952706     1.564234      1.560278   \n",
      "2800  608.315795   0.470466  0.948821     1.681705      1.560769   \n",
      "2801  630.759446   0.470466  0.944810     1.764701      1.540380   \n",
      "2802  887.310743   0.643761  0.947380     1.707933      1.530231   \n",
      "\n",
      "      Eccentricity    Extent  Convex hull(convex area)  Type  \n",
      "0         0.620313  0.681193                   23237.5     0  \n",
      "1         0.592117  0.656353                   24065.5     0  \n",
      "2         0.613828  0.683620                   23144.0     0  \n",
      "3         0.598733  0.685360                   23385.0     0  \n",
      "4         0.610574  0.714800                   20041.0     0  \n",
      "...            ...       ...                       ...   ...  \n",
      "2798      0.748511  0.725739                   19840.5     2  \n",
      "2799      0.767615  0.714016                   18068.0     2  \n",
      "2800      0.767783  0.718999                   18455.0     2  \n",
      "2801      0.760626  0.738191                   18989.0     2  \n",
      "2802      0.756930  0.722429                   38721.0     2  \n",
      "\n",
      "[2790 rows x 13 columns]\n"
     ]
    }
   ],
   "source": [
    "#### Standardize the data ##############################################################################################################################################\n",
    "standardized_scaler = StandardScaler()\n",
    "x_train = standardized_scaler.fit_transform(x_train)\n",
    "x_test = standardized_scaler.transform(x_test)\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd97119f-0e5e-4fde-9f43-db0060988c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Convert data for neural network model #############################################################################################################################\n",
    "x_train_tensor = torch.tensor(x_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32)\n",
    "\n",
    "x_test_tensor = torch.tensor(x_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test.to_numpy(), dtype=torch.float32)\n",
    "\n",
    "train_dataset = TensorDataset(x_train_tensor, y_train_tensor)\n",
    "test_dataset = TensorDataset(x_test_tensor, y_test_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a7853b2c-d65a-4cd8-ae98-371cccc9d979",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Neural network model ##############################################################################################################################################\n",
    "\n",
    "#### Base neural network ####\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, size_of_input, size_of_hidden, num_classes):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.layerOne = nn.Linear(size_of_input, size_of_hidden)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.layerTwo = nn.Linear(size_of_hidden, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layerOne(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.layerTwo(x)\n",
    "        return x\n",
    "\n",
    "#### Set the parameters for the basic neural network model ####\n",
    "size_of_input = 12\n",
    "num_classes = 3\n",
    "\n",
    "#### R Prop training algorithm####\n",
    "def training_model_rprop(size_of_hidden, learning_rate, num_epochs, train_loader):\n",
    "    model = NeuralNetwork(size_of_input, size_of_hidden, num_classes)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Rprop(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        for inputs, labels in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            labels = labels.long()\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    return loss.item(), model\n",
    "\n",
    "\n",
    "#### Adam optimiser ####\n",
    "def training_model_adam(size_of_hidden, learning_rate, num_epochs, train_loader):\n",
    "    model = NeuralNetwork(size_of_input, size_of_hidden, num_classes)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        for inputs, labels in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            labels = labels.long()\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "    return loss.item(), model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8acb86b6-eca8-4323-9ad1-41565b6e0a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Function to train and evaluate model using K-Fold ####\n",
    "def evaluate_model_kfold(optimizer_type, size_of_hidden, learning_rate, num_epochs, k_folds=5):\n",
    "    kfold = KFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
    "\n",
    "    performance_scores = []\n",
    "    loss_scores = [] \n",
    "    \n",
    "    for fold, (train_idx, val_idx) in enumerate(kfold.split(x_train_tensor)):\n",
    "        # Split data into training and validation sets for this fold\n",
    "        x_train_fold = x_train_tensor[train_idx]\n",
    "        y_train_fold = y_train_tensor[train_idx]\n",
    "        x_val_fold = x_train_tensor[val_idx]\n",
    "        y_val_fold = y_train_tensor[val_idx]\n",
    "        \n",
    "        train_dataset_fold = TensorDataset(x_train_fold, y_train_fold)\n",
    "        train_loader_fold = DataLoader(train_dataset_fold, batch_size=16, shuffle=True)\n",
    "\n",
    "        if optimizer_type == 'adam':\n",
    "            loss, model = training_model_adam(size_of_hidden, learning_rate, num_epochs, train_loader_fold)\n",
    "        elif optimizer_type == 'rprop':\n",
    "            loss, model = training_model_rprop(size_of_hidden, learning_rate, num_epochs, train_loader_fold)\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown optimizer type: {optimizer_type}\")\n",
    "            \n",
    "        loss_scores.append(loss)\n",
    "        \n",
    "        # Evaluate the model on the validation fold\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            outputs = model(x_val_fold)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            accuracy = accuracy_score(y_val_fold.numpy(), predicted.numpy())\n",
    "        \n",
    "        performance_scores.append(accuracy)\n",
    "    \n",
    "    # Calculate the average performance and standard deviation of the training algorithms\n",
    "    avg_performance = np.mean(performance_scores)\n",
    "    std_performance = np.std(performance_scores)\n",
    "    avg_loss = np.mean(loss_scores)\n",
    "    \n",
    "    print(f\"Average {optimizer_type} performance across {k_folds} folds: {avg_performance:.4f}, Std: {std_performance:.4f}\")\n",
    "    print(f\"Average {optimizer_type} loss across {k_folds} folds: {avg_loss:.4f}\")\n",
    "    \n",
    "    return avg_performance, std_performance, avg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3059bab1-5705-410b-84cb-e37efa233172",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model with hidden size 6, learning rate 0.001\n",
      "Average adam performance across 5 folds: 0.6411, Std: 0.0256\n",
      "Average adam loss across 5 folds: 0.6639\n",
      "Average rprop performance across 5 folds: 0.5090, Std: 0.0127\n",
      "Average rprop loss across 5 folds: 1.0266\n",
      "Evaluating model with hidden size 6, learning rate 0.01\n",
      "Average adam performance across 5 folds: 0.6810, Std: 0.0389\n",
      "Average adam loss across 5 folds: 0.6042\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameter combination \n",
    "hidden_sizes = [6, 8, 10, 16]\n",
    "learning_rates = [0.001, 0.01]\n",
    "num_epochs = 50\n",
    "\n",
    "# Iterate through different hyperparameter combinations\n",
    "for hidden_size, lr in product(hidden_sizes, learning_rates):\n",
    "    print(f\"Evaluating model with hidden size {hidden_size}, learning rate {lr}\")\n",
    "    \n",
    "    # Evaluate with Adam optimizer\n",
    "    evaluate_model_kfold(optimizer_type='adam', size_of_hidden=hidden_size, learning_rate=lr, num_epochs=num_epochs, k_folds=5)\n",
    "    \n",
    "    # Evaluate with RProp optimizer\n",
    "    evaluate_model_kfold(optimizer_type='rprop', size_of_hidden=hidden_size, learning_rate=lr, num_epochs=num_epochs, k_folds=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55bc6eec-08c1-4bc0-ab6b-70d7a0723dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Test rprop algorithm on testing data ####\n",
    "def evaluate_rprop_on_test(size_of_hidden, learning_rate, num_epochs):\n",
    "    final_loss, trained_model = training_model_rprop(size_of_hidden, learning_rate, num_epochs, test_loader)\n",
    "    \n",
    "    trained_model.eval()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    with torch.no_grad(): \n",
    "        outputs = trained_model(x_test_tensor) \n",
    "        labels = y_test_tensor.long()\n",
    "        test_loss = criterion(outputs, labels).item()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        \n",
    "        accuracy = accuracy_score(y_test_tensor.numpy(), predicted.numpy())        \n",
    "        print(f\"RProp Model Accuracy on Test Set: {accuracy:.4f}\")\n",
    "        print(f\"RProp Model Test Loss: {test_loss:.4f}\")\n",
    "    \n",
    "    return accuracy, test_loss\n",
    "\n",
    "size_of_hidden = 16\n",
    "learning_rate = 0.01\n",
    "num_epochs = 50\n",
    "evaluate_rprop_on_test(size_of_hidden, learning_rate, num_epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d7af172-5369-46ae-8c18-59c4450e54ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Test adam algorithm on testing data ####\n",
    "def evaluate_adam_on_test(size_of_hidden, learning_rate, num_epochs):\n",
    "    final_loss, trained_model = training_model_adam(size_of_hidden, learning_rate, num_epochs, test_loader)\n",
    "    \n",
    "    trained_model.eval()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    with torch.no_grad(): \n",
    "        outputs = trained_model(x_test_tensor)\n",
    "        labels = y_test_tensor.long()\n",
    "        test_loss = criterion(outputs, labels).item()\n",
    "        \n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        \n",
    "        accuracy = accuracy_score(y_test_tensor.numpy(), predicted.numpy())        \n",
    "        print(f\"Adam Model Accuracy on Test Set: {accuracy:.4f}\")\n",
    "        print(f\"Adam Model Test Loss: {test_loss:.4f}\")\n",
    "\n",
    "    return accuracy, test_loss\n",
    "\n",
    "size_of_hidden = 16\n",
    "learning_rate = 0.01\n",
    "num_epochs = 50\n",
    "evaluate_adam_on_test(size_of_hidden, learning_rate, num_epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb829df-43cc-4f36-b894-24fb71f9f305",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Hybrid model ####\n",
    "def hybrid_training_model(size_of_hidden, learning_rate_adam, learning_rate_rprop, num_epochs, train_loader):\n",
    "    model = NeuralNetwork(size_of_input, size_of_hidden, num_classes)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    optimizer_adam = optim.Adam(model.parameters(), lr=learning_rate_adam)\n",
    "    optimizer_rprop = optim.Rprop(model.parameters(), lr=learning_rate_rprop)\n",
    "\n",
    "    weight_update_correlations = [] # Store the weight update differences between Adam and RProp\n",
    "    final_loss = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_loss = 0.0 \n",
    "        for inputs, labels in train_loader:\n",
    "            optimizer_adam.zero_grad()\n",
    "            optimizer_rprop.zero_grad()\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            labels = labels.long()\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "\n",
    "            adam_grads = [param.grad.clone().detach() for param in model.parameters()]\n",
    "            rprop_grads = [param.grad.clone().detach() for param in model.parameters()]\n",
    "\n",
    "            with torch.no_grad():\n",
    "                for param, adam_grad, rprop_grad in zip(model.parameters(), adam_grads, rprop_grads):\n",
    "                    avg_update = (adam_grad + rprop_grad) / 2.0\n",
    "                    param.grad.copy_(avg_update)\n",
    "\n",
    "            for adam_grad, rprop_grad in zip(adam_grads, rprop_grads):\n",
    "                if adam_grad.numel() > 0 and rprop_grad.numel() > 0:\n",
    "                    correlation = torch.corrcoef(torch.stack([adam_grad.flatten(), rprop_grad.flatten()]))\n",
    "                    weight_update_correlations.append(correlation[0, 1].item()) \n",
    "\n",
    "            optimizer_adam.step()\n",
    "            optimizer_rprop.step()\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            \n",
    "    final_loss = epoch_loss / len(train_loader)      \n",
    "    avg_correlation = np.mean(weight_update_correlations)\n",
    "    print(f\"Average correlation between Adam and RProp updates: {avg_correlation:.4f}\")\n",
    "\n",
    "    return final_loss, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8dec21c-4dfe-47fb-a571-cc8abf92a25f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Evaluate hybrid model with testing data ####\n",
    "def evaluate_hybrid_model_on_test(size_of_hidden, learning_rate_adam, learning_rate_rprop, num_epochs, train_loader, x_test_tensor, y_test_tensor):\n",
    "    final_loss, trained_model = hybrid_training_model(size_of_hidden=size_of_hidden, learning_rate_adam=learning_rate_adam,\n",
    "                                                      learning_rate_rprop=learning_rate_rprop, num_epochs=num_epochs, train_loader=test_loader)\n",
    "\n",
    "    trained_model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = trained_model(x_test_tensor)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        accuracy = accuracy_score(y_test_tensor.numpy(), predicted.numpy())\n",
    "\n",
    "    print(f\"Test set accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Final training loss: {final_loss:.4f}\")\n",
    "\n",
    "    return accuracy, final_loss\n",
    "\n",
    "\n",
    "# Hyperparameters for hybrid model \n",
    "size_of_hidden = 16\n",
    "learning_rate_adam = 0.01\n",
    "learning_rate_rprop = 0.01\n",
    "num_epochs = 50\n",
    "accuracy, final_loss = evaluate_hybrid_model_on_test(size_of_hidden=size_of_hidden, learning_rate_adam=learning_rate_adam, \n",
    "                                                     learning_rate_rprop=learning_rate_rprop, num_epochs=num_epochs, train_loader=test_loader, \n",
    "                                                     x_test_tensor=x_test_tensor, y_test_tensor=y_test_tensor)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
